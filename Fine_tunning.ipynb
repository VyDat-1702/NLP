{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uj4PJjVEpn74"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq, Seq2SeqTrainer\n",
        "import evaluate\n",
        "from datasets import Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Import and read dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GpIdRV9NpqXf"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/clean_vie.txt'\n",
        "def load_data_from_file(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    en_texts, vi_texts = zip(*[line.strip().split(\"\\t\") for line in lines])\n",
        "\n",
        "    return {\"en\": list(en_texts), \"vi\": list(vi_texts)}\n",
        "\n",
        "data = load_data_from_file(data_path)\n",
        "\n",
        "ds = Dataset.from_dict(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. Tokenize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ysUCDdKcpyiX"
      },
      "outputs": [],
      "source": [
        "model_name = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. Encoding, Pre-proccessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfC0wWX9p51-"
      },
      "outputs": [],
      "source": [
        "MAX_LEN = 75\n",
        "\n",
        "def preprocess_function(examples):\n",
        "    input_ids = tokenizer(\n",
        "        examples[\"en\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN\n",
        "    )[\"input_ids\"]\n",
        "\n",
        "    labels = tokenizer(\n",
        "        examples[\"vi\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN\n",
        "    )[\"input_ids\"]\n",
        "\n",
        "    labels = [[-100 if token == tokenizer.pad_token_id else token for token in label] for label in labels]\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": torch.tensor(input_ids),\n",
        "        \"labels\": torch.tensor(labels)\n",
        "    }\n",
        "\n",
        "preprocessed_ds = ds.map(preprocess_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "4. Load mBART50 model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsQwbIaZp8W4"
      },
      "outputs": [],
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "5. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEVtj9m4p_HH"
      },
      "outputs": [],
      "source": [
        "metric = evaluate.load(\"sacrebleu\")\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    preds, labels = eval_preds\n",
        "\n",
        "    if isinstance(preds, tuple):\n",
        "        preds = preds[0]\n",
        "\n",
        "    preds = np.where(preds != -100, preds, tokenizer.pad_token_id)\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "\n",
        "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    return {\"bleu\": result[\"score\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "6. Trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7vaDZXQWqJwS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
        "\n",
        "training_args = Seq2SeqTrainingArguments(\n",
        "    output_dir=\"./en-vi-mbart50\",\n",
        "    logging_dir=\"logs\",\n",
        "    logging_steps=1000,\n",
        "    predict_with_generate=True,\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=1000,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=1000,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=2,\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=preprocessed_ds,\n",
        "    eval_dataset=preprocessed_ds,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMi1pGSgrtt1"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GuYvXeCe4rnc"
      },
      "outputs": [],
      "source": [
        "tokenizer.save_pretrained(\"/content/en-vi-mbart50\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HO9D9atsGLZ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer, pipeline\n",
        "\n",
        "model_path = \"/content/en-vi-mbart50/checkpoint-1848\"\n",
        "\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_path)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/en-vi-mbart50\")\n",
        "\n",
        "translator = pipeline(\"translation_en_to_vi\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "text = \"What are you doing\"\n",
        "translated_text = translator(text, num_beams=5)\n",
        "print(translated_text[0]['translation_text'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U6_HZYUu5NXz"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
